{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    infile_path = \"../data/multi_omics_master_heatmap_table.tsv.gz\"\n",
    "    data = pd.read_csv(infile_path, sep=\"\\t\", low_memory=False, compression=\"gzip\")\n",
    "    data[\"Species_Strain\"] = data[\"Species\"] + \" \" + data[\"Strain\"]\n",
    "    data.replace(regex={\n",
    "        r'^Proteomics MS1 DDA':'Proteomics_MS1', \n",
    "        r'^Proteomics MS2 DIA/SWATH':'Proteomics_MS2', \n",
    "        r'^Metabolomics GC-MS':'Metabolomics_GCMS',\n",
    "        r'^Metabolomics LC-MS':'Metabolomics_LCMS',\n",
    "        r';':'_',\n",
    "    }, inplace=True)\n",
    "    # for rnaseq, the id columns are swapped!\n",
    "    rnaseq = data[\"Type_of_Experiment\"] == \"RNA-Seq\"\n",
    "    data.loc[rnaseq,['entity_id','additional_id']] = data.loc[rnaseq,['additional_id','entity_id']].values\n",
    "    data = data[data['entity_id'].notna()]\n",
    "    return data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat and standardise data to match below sample\n",
    "# columns are features, rows are samples\n",
    "#\n",
    "#         MEGF9    GINS2   FAM13A    CPT1A    SNX10   TRIM45     ELP2    ALOX5\n",
    "# A0FJ 5.340520 5.353213 4.849088 6.191176 4.591788 3.150658 6.581283 2.657454\n",
    "# A13E 5.292700 3.639934 4.924028 6.139249 3.981164 3.280685 7.150755 2.979337\n",
    "# A0G0 5.015130 4.453413 4.350443 6.504090 3.073839 2.542987 6.430628 3.373541\n",
    "\n",
    "def get_unique(data):\n",
    "    sp_strain = data[\"Species_Strain\"].unique()\n",
    "    omics = data[\"Type_of_Experiment\"].unique()\n",
    "    treat = data[\"Treatment_Type\"].unique()\n",
    "    return sp_strain, omics, treat\n",
    "    \n",
    "def split_modality(data, omics):\n",
    "    \"\"\"Take whole dataframe, separate into omics for a strain\"\"\"\n",
    "    data = data.loc[\n",
    "        (data[\"Type_of_Experiment\"].str.contains(omics))\n",
    "    ]\n",
    "    data[\"entity_id\"] = data[\"entity_id\"] + \"_\" + data[\"Type_of_Experiment\"]\n",
    "    return data[[\"entity_id\", \"Treatment_Type\", \"replicate_name\", \"Units\", \"Log_Counts\"]].set_index([\"entity_id\"])\n",
    "\n",
    "def split_replicate(data, replicate_name):\n",
    "    \"\"\"Split into replicate\"\"\"\n",
    "    return data[data[\"replicate_name\"] == replicate_name]\n",
    "\n",
    "def split_treatment(data, treatment, replicate_name):\n",
    "    \"\"\"Split into treatment\"\"\"\n",
    "    data = pd.DataFrame(data[data[\"Treatment_Type\"] == treatment][\"Log_Counts\"]).T\n",
    "    data.rename({\"Log_Counts\":replicate_name}, inplace=True)\n",
    "    data.columns.name = None\n",
    "    return data\n",
    "\n",
    "def split_data(data, omics):\n",
    "    \"\"\"Split data into diablo-compatible format\"\"\"\n",
    "    modalities = split_modality(data, omics)\n",
    "    treatments = modalities[\"Treatment_Type\"].unique()\n",
    "    \n",
    "    samples = list()\n",
    "    for rep in modalities[\"replicate_name\"].unique():\n",
    "        replicate = split_replicate(modalities, rep)\n",
    "        for treatment in treatments:\n",
    "            sample = split_treatment(replicate, treatment, rep)\n",
    "            if sample.empty:\n",
    "                continue\n",
    "            else:\n",
    "                sample = sample.T.groupby(by=sample.T.index, as_index=True).mean()\n",
    "                samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "def rescale_log(data, base=2):\n",
    "    data = base**data\n",
    "    data = data.fillna(0) + 1\n",
    "    return np.log2(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick ids corresponding to strains of interest\n",
    "# we want strains represented across all omics\n",
    "def find_multiomics_strains(data, omic_main):\n",
    "    print(omic_main)\n",
    "    omic_data = [set(data.loc[(data[\"Type_of_Experiment\"].str.contains(omic))][\"Strain\"].unique().tolist()) for omic in omic_main]\n",
    "    omic_strains = omic_data[0].intersection(omic_data[1], omic_data[2], omic_data[3], omic_data[4])\n",
    "    return omic_strains\n",
    "\n",
    "def find_sample_names(data, omic_strains):\n",
    "    print(omic_strains)\n",
    "    omic_names = [data.loc[(data[\"Strain\"].str.contains(strain))][\"replicate_name\"].unique() for strain in omic_strains]\n",
    "    sample_names = [data.loc[(data[\"Strain\"] == strain)][\"replicate_name\"].unique().tolist() for strain in omic_strains] \n",
    "    return sample_names\n",
    "\n",
    "def extract_info(data, sample_names):\n",
    "    treatments = data.drop_duplicates([\"replicate_name\", \"Treatment_Type\"])\n",
    "    treatments = [treatments.loc[(treatments[\"replicate_name\"].isin(sample_name))] for sample_name in sample_names]\n",
    "    treatments = [t[[\"replicate_name\", \"Treatment_Type\"]].set_index(\"replicate_name\") for t in treatments]\n",
    "    return treatments\n",
    "\n",
    "def extract_data(normalised, strain_samples, strain):\n",
    "    print(strain)\n",
    "    return [x.loc[strain_samples[strain].index].fillna(0) + 1 for x in normalised]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tche0054/miniconda3/envs/graph/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/tche0054/miniconda3/envs/graph/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Proteomics_MS1', 'Proteomics_MS2', 'Metabolomics_GCMS', 'Metabolomics_LCMS', 'RNA-Seq']\n",
      "{'SP444', '5448', 'MS14385', 'AJ218', 'AJ055', 'BPH2819', 'B36', 'BPH2986', 'MS14386', 'BPH2947', 'BPH2900', 'AJ292', 'PS006', 'BPH2760', 'KPC2', 'HKU419', 'MS14384', '03-311-0071', 'PS003', '04153260899A', 'MS14387'}\n",
      "SP444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tche0054/miniconda3/envs/graph/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5448\n",
      "MS14385\n",
      "AJ218\n",
      "AJ055\n",
      "BPH2819\n",
      "B36\n",
      "BPH2986\n",
      "MS14386\n",
      "BPH2947\n",
      "BPH2900\n",
      "AJ292\n",
      "PS006\n",
      "BPH2760\n",
      "KPC2\n",
      "HKU419\n",
      "MS14384\n",
      "03-311-0071\n",
      "PS003\n",
      "04153260899A\n",
      "MS14387\n"
     ]
    }
   ],
   "source": [
    "def main(data):\n",
    "    omics_main = list(data[\"Type_of_Experiment\"].unique())\n",
    "    # for each omics platform, extract a unique feature id\n",
    "    samples = [split_data(data, omic) for omic in omics_main]\n",
    "    # \n",
    "    samples = [pd.concat(sample, axis=1, join=\"outer\") for sample in samples]\n",
    "    # this is not log scale data\n",
    "    lfq = [x.fillna(0) for x in samples[:1]]\n",
    "    # add offset by unlogging > +1 > relogging\n",
    "    log = [rescale_log(x) for x in samples[1:]]\n",
    "    normalised = lfq + log\n",
    "    normalised = [x.T for x in normalised]\n",
    "\n",
    "    omic_strains = find_multiomics_strains(data, omics_main)\n",
    "    sample_names = find_sample_names(data, omic_strains)\n",
    "    sample_info = extract_info(data, sample_names)\n",
    "    strain_samples = dict(zip(omic_strains, sample_info))    \n",
    "    \n",
    "    for key in strain_samples.keys():\n",
    "        strain = extract_data(normalised, strain_samples, key)\n",
    "        for omic, data in tuple(zip(omics_main, strain)):\n",
    "            outfile_path = \"\".join([\"../results/\", key, \"_\", omic, \".tsv\"])\n",
    "            info_path = \"\".join([\"../results/\", key, \"_info.tsv\"])\n",
    "            data.to_csv(outfile_path, sep=\"\\t\")\n",
    "            strain_samples[key].to_csv(info_path, sep=\"\\t\")\n",
    "\n",
    "main(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:graph]",
   "language": "python",
   "name": "conda-env-graph-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
